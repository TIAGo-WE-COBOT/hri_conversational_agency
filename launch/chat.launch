<launch>
    <!-- Set the path to the environment -->
    <arg name = "venv"      default = "$(optenv HRI_CONVERSATIONAL_AGENCY_VENV)" />
    <arg name = "backend"   default = "dummy" />
    <arg name = "model"     default = "None" />
    <arg name = "model_path"    default = "$(find hri_conversational_agency)/models" />
    <arg name = "ns"        default = "conversational_agent" />
    <arg name = "request_topic"  default = "request"   />
    <arg name = "response_topic" default = "response"  />


    <!-- Launch the node to chat with the conversational agent -->
    <node pkg = "hri_conversational_agency" type = "chat.py" name = "chat" ns="$(arg ns)"
    output = "screen" launch-prefix="$(arg venv)" 
    args = "--backend $(arg backend) --model $(arg model) --model_path $(arg model_path)" unless="$(eval backend == 'langchain')">
        <remap from = "request"   to = "$(arg request_topic)" />
        <remap from = "response"  to = "$(arg response_topic)" />
    </node>
    <node pkg = "hri_conversational_agency" type = "chat_extended.py" name = "chat" ns="$(arg ns)"
    output = "screen" launch-prefix="$(arg venv)"
    if="$(eval backend == 'langchain')">
        <remap from = "request"   to = "$(arg request_topic)" />
        <remap from = "response"  to = "$(arg response_topic)" />
    </node>
</launch>
