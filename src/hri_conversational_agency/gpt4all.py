"""
A conversational agent that generates responses to user input based on GPT4All models.
"""
import os

from gpt4all import GPT4All

from hri_conversational_agency.base import BaseChatter
from hri_conversational_agency.logger import Logger

class GPT4AllChatter(BaseChatter):
    def __init__(self, model="Meta-Llama-3-8B-Instruct.Q4_0.gguf", model_path=None, device='gpu'):
        """Initialize the GPT4AllChatter object.

        Args:
            model (str, optional): The name of the model to be used. Defaults to "Meta-Llama-3-8B-Instruct.Q4_0.gguf". If path is provided, the model will be loaded from the path. If path is not provided, the model will be loaded from the default GPT4All path.
            model_path (str, optional): The path to the model. If None, the model will be loaded from the default GPT4All path. Defaults to None.
        """
        self.log = Logger(agent_name=model)
        self.log.logfile_open()
        for model_dict in GPT4All.list_models():
            print(model_dict['name'], '\t', model_dict['filename'])
        self.model=GPT4All(model, model_path)

    def generate_response(self, request):
        """Given a string input, generate a response using the selected model. The method will log the input and output for later inspection of the dialogue.

        Args:
            request (str): The input string to be processed by the model.

        Returns:
            str: The output string generated by the model.
        """
        if not hasattr(self, 'chat'):
            self.chat = open(self.model.chat_session())
        self.log.log_input(request)
        response = self.model.generate(request)
        # Log the output for later inspection of the dialogue
        self.log.log_output(response)
        return response

    def set_history(self, history):
        """Receive a list of tuples (role, content) to set the history of the agent. The method is currently not implemented for GPT4All backend. The method is only here to comply with the interface of the other agents.
        The method will raise a NotImplementedError if called.

        Args:
            history ([(str, str)]): List of tuples (role, content) to set the history of the agent.

        Raises:
            NotImplementedError: The method is only here to comply with the interface of the other agents.
        """
        raise NotImplementedError("The `set_history` method is not implemented for GPT4All backend.")

    def set_system_prompt(self, prompt):
        """Receive a system prompt to set the system prompt of the agent. The method is currently not implemented for GPT4All backend. The method is only here to comply with the interface of the other agents.
        The method will raise a NotImplementedError if called.

        Args:
            prompt (str): System prompt to set the system prompt of the agent.

        Raises:
            NotImplementedError: The method is only here to comply with the interface of the other agents.
        """
        raise NotImplementedError("The `set_system_prompt` method is not implemented for GPT4All backend.")
    
    def on_shutdown(self):
        self.log.logfile_close()
        self.chat.close()
        self.model.close()

